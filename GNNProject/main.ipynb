{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840084c3-f771-42c9-be68-2b04e6acab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6600\n",
      "Number of edges: 50897\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nodes_df = pd.read_csv('nodes.csv' , header = None , names=['node_attribute'], index_col=0)\n",
    "edges_df = pd.read_csv('edges.csv')\n",
    "\n",
    "\n",
    "nodes_list = [(index, ast.literal_eval(row.node_attribute))  for index, row in nodes_df.iterrows()]\n",
    "edges_list = [(row.From, row.To) for index, row in edges_df.iterrows()]\n",
    "\n",
    "number_of_days = 1448\n",
    "nodes_list_vec = []\n",
    "for index,dict_node in nodes_list:\n",
    "    vec = np.zeros(number_of_days,dtype=np.float32)\n",
    "    for day, count in dict_node.items():\n",
    "        vec[day] = count\n",
    "\n",
    "    nodes_list_vec.append((index, vec))\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "Graph = nx.DiGraph()\n",
    "for node_id, node_attr_vec in nodes_list_vec:\n",
    "    Graph.add_node(node_id, x = node_attr_vec)\n",
    "Graph.add_edges_from(edges_list)\n",
    "\n",
    "print(f\"Number of nodes: {nx.number_of_nodes(Graph)}\")\n",
    "print(f\"Number of edges: {nx.number_of_edges(Graph)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87609ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\torch_geometric\\utils\\convert.py:278: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  data_dict[key] = torch.as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[6600, 1448], edge_index=[2, 50897])\n",
      "Data is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# Convert to PyG data\n",
    "data = from_networkx(Graph)\n",
    "\n",
    "# Convert node attributes to tensor and move to device\n",
    "X = torch.stack([torch.tensor(attr['x'], dtype=torch.float32) for _, attr in Graph.nodes(data=True)])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X = X.to(device)\n",
    "data.x = X\n",
    "data = data.to(device)\n",
    "\n",
    "print(data)\n",
    "print(f\"Data is on device: {data.x.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7be0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase1_score = []  #Holds every node's phase 1 score , index number corresponds to node id\n",
    "def phase1(node_list_vec, start_day = 0 , current_day=1448):\n",
    "    for node_id, node_attr_vec in node_list_vec:\n",
    "        mean = np.mean(node_attr_vec[start_day:current_day])\n",
    "        std = np.std(node_attr_vec[start_day:current_day])\n",
    "        today_score = (node_attr_vec[current_day] -mean) / std if std > 0 else 0\n",
    "        phase1_score.append(today_score)\n",
    "\n",
    "phase1(nodes_list_vec, start_day=0, current_day=1447)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7be0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda:0\n",
      "Epoch: 010, Loss: 9.2595\n",
      "Epoch: 010, Loss: 9.2595\n",
      "Epoch: 020, Loss: 2.2327\n",
      "Epoch: 020, Loss: 2.2327\n",
      "Epoch: 030, Loss: 1.4871\n",
      "Epoch: 030, Loss: 1.4871\n",
      "Epoch: 040, Loss: 1.3864\n",
      "Epoch: 040, Loss: 1.3864\n",
      "Epoch: 050, Loss: 1.3759\n",
      "Epoch: 050, Loss: 1.3759\n",
      "Epoch: 060, Loss: 1.3574\n",
      "Epoch: 060, Loss: 1.3574\n",
      "Epoch: 070, Loss: 1.3523\n",
      "Epoch: 070, Loss: 1.3523\n",
      "Epoch: 080, Loss: 1.3569\n",
      "Epoch: 080, Loss: 1.3569\n",
      "Epoch: 090, Loss: 1.3322\n",
      "Epoch: 090, Loss: 1.3322\n",
      "Epoch: 100, Loss: 1.3333\n",
      "Epoch: 100, Loss: 1.3333\n",
      "Epoch: 110, Loss: 1.3135\n",
      "Epoch: 110, Loss: 1.3135\n",
      "Epoch: 120, Loss: 1.3264\n",
      "Epoch: 120, Loss: 1.3264\n",
      "Epoch: 130, Loss: 1.2990\n",
      "Epoch: 130, Loss: 1.2990\n",
      "Epoch: 140, Loss: 1.2811\n",
      "Epoch: 140, Loss: 1.2811\n",
      "Epoch: 150, Loss: 1.2909\n",
      "Epoch: 150, Loss: 1.2909\n",
      "Epoch: 160, Loss: 1.2618\n",
      "Epoch: 160, Loss: 1.2618\n",
      "Epoch: 170, Loss: 1.2576\n",
      "Epoch: 170, Loss: 1.2576\n",
      "Epoch: 180, Loss: 1.2411\n",
      "Epoch: 180, Loss: 1.2411\n",
      "Epoch: 190, Loss: 1.2481\n",
      "Epoch: 190, Loss: 1.2481\n",
      "Epoch: 200, Loss: 1.2473\n",
      "Final embeddings device: cuda:0\n",
      "Epoch: 200, Loss: 1.2473\n",
      "Final embeddings device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "phase2_score = [] #Holds every node's phase 2 score , index number corresponds to node id\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels , num_layers=3 , dropout = 0.3):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p = self.dropout, training= self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x \n",
    "\n",
    "in_channels = data.num_node_features\n",
    "hidden_channels = 128 \n",
    "out_channels = 64 \n",
    "\n",
    "model = GraphSAGE(in_channels, hidden_channels, out_channels).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr =0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model(data.x, data.edge_index)\n",
    "\n",
    "    pos_edge_index = data.edge_index\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        num_neg_samples=pos_edge_index.size(1),\n",
    "    ).to(device)  \n",
    "\n",
    "    pos_similarity = (z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=1)\n",
    "    pos_loss = F.logsigmoid(pos_similarity).mean()\n",
    "\n",
    "    neg_similarity = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=1)\n",
    "    neg_loss = F.logsigmoid(-neg_similarity).mean()\n",
    "\n",
    "    loss = -pos_loss - neg_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), z\n",
    "\n",
    "print(f\"Training on device: {next(model.parameters()).device}\")\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss, embeddings = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model(data.x, data.edge_index)\n",
    "    print(f\"Final embeddings device: {z.device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
