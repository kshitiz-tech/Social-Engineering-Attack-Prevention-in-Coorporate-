{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840084c3-f771-42c9-be68-2b04e6acab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6600\n",
      "Number of edges: 50897\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nodes_df = pd.read_csv('nodes.csv' , header = None , names=['node_attribute'], index_col=0)\n",
    "edges_df = pd.read_csv('edges.csv')\n",
    "\n",
    "\n",
    "nodes_list = [(index, ast.literal_eval(row.node_attribute))  for index, row in nodes_df.iterrows()]\n",
    "edges_list = [(row.From, row.To) for index, row in edges_df.iterrows()]\n",
    "\n",
    "number_of_days = 1448\n",
    "nodes_list_vec = []\n",
    "for index,dict_node in nodes_list:\n",
    "    vec = np.zeros(number_of_days,dtype=np.float32)\n",
    "    for day, count in dict_node.items():\n",
    "        vec[day] = count\n",
    "\n",
    "    nodes_list_vec.append((index, vec))\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "Graph = nx.DiGraph()\n",
    "for node_id, node_attr_vec in nodes_list_vec:\n",
    "    Graph.add_node(node_id, x = node_attr_vec)\n",
    "Graph.add_edges_from(edges_list)\n",
    "\n",
    "print(f\"Number of nodes: {nx.number_of_nodes(Graph)}\")\n",
    "print(f\"Number of edges: {nx.number_of_edges(Graph)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87609ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\torch_geometric\\__init__.py:4: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: Could not load this library: C:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\Lib\\site-packages\\libpyg.pyd\n",
      "  import torch_geometric.typing\n",
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\torch_geometric\\__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not load this library: C:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\Lib\\site-packages\\torch_scatter\\_version_cuda.pyd\n",
      "  import torch_geometric.typing\n",
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\torch_geometric\\__init__.py:4: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: Could not load this library: C:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\Lib\\site-packages\\torch_cluster\\_version_cuda.pyd\n",
      "  import torch_geometric.typing\n",
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\torch_geometric\\__init__.py:4: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: Could not load this library: C:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\Lib\\site-packages\\torch_spline_conv\\_version_cuda.pyd\n",
      "  import torch_geometric.typing\n",
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\torch_geometric\\__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not load this library: C:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\Lib\\site-packages\\torch_sparse\\_version_cuda.pyd\n",
      "  import torch_geometric.typing\n",
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\torch_geometric\\utils\\convert.py:278: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  data_dict[key] = torch.as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[6600, 1448], edge_index=[2, 50897])\n",
      "Data is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# Convert to PyG data\n",
    "data = from_networkx(Graph)\n",
    "\n",
    "# Convert node attributes to tensor and move to device\n",
    "X = torch.stack([torch.tensor(attr['x'], dtype=torch.float32) for _, attr in Graph.nodes(data=True)])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X = X.to(device)\n",
    "data.x = X\n",
    "data = data.to(device)\n",
    "\n",
    "print(data)\n",
    "print(f\"Data is on device: {data.x.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7be0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase1_score = []  #Holds every node's phase 1 score , index number corresponds to node id\n",
    "def phase1(node_list_vec, start_day = 0 , current_day=1448):\n",
    "    for node_id, node_attr_vec in node_list_vec:\n",
    "        mean = np.mean(node_attr_vec[start_day:current_day])\n",
    "        std = np.std(node_attr_vec[start_day:current_day])\n",
    "        today_score = (node_attr_vec[current_day] -mean) / std if std > 0 else 0\n",
    "        phase1_score.append(today_score)\n",
    "\n",
    "phase1(nodes_list_vec, start_day=0, current_day=1447)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df7be0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda:0\n",
      "Epoch: 010, Loss: 3.7006\n",
      "Epoch: 020, Loss: 1.4405\n",
      "Epoch: 030, Loss: 1.4223\n",
      "Epoch: 040, Loss: 1.4160\n",
      "Epoch: 050, Loss: 1.4053\n",
      "Epoch: 060, Loss: 1.4091\n",
      "Epoch: 070, Loss: 1.4090\n",
      "Epoch: 080, Loss: 1.3777\n",
      "Epoch: 090, Loss: 1.3536\n",
      "Epoch: 100, Loss: 1.3382\n",
      "Epoch: 110, Loss: 1.3326\n",
      "Epoch: 120, Loss: 1.3286\n",
      "Epoch: 130, Loss: 1.3271\n",
      "Epoch: 140, Loss: 1.3299\n",
      "Epoch: 150, Loss: 1.3212\n",
      "Epoch: 160, Loss: 1.3275\n",
      "Epoch: 170, Loss: 1.3209\n",
      "Epoch: 180, Loss: 1.3226\n",
      "Epoch: 190, Loss: 1.3174\n",
      "Epoch: 200, Loss: 1.3388\n",
      "Final embeddings:\n",
      "\n",
      "Embeddings shape: torch.Size([6600, 64])\n",
      "Sample of first 5 nodes:\n",
      "tensor([[ 9.2174e-02,  1.1157e-01, -1.8774e-02, -1.0982e-01,  1.9369e-02,\n",
      "          5.2376e-02, -2.6877e-02, -1.5991e-03, -1.9877e-02,  6.9069e-02,\n",
      "          4.5941e-02, -3.6317e-02,  8.2629e-02,  1.0024e-01, -9.3068e-02,\n",
      "         -1.8002e-02, -2.1818e-02, -1.0936e-01, -1.0695e-01, -8.0348e-02,\n",
      "         -1.1923e-01,  1.2103e-01,  2.2726e-02, -7.2719e-03, -1.0334e-02,\n",
      "          1.1574e-01, -2.2247e-02, -1.6334e-02, -9.0178e-02,  8.0166e-03,\n",
      "         -1.2147e-01, -2.1103e-02, -8.0933e-02,  7.8052e-02,  1.1703e-02,\n",
      "          4.2929e-02, -4.8632e-02,  5.1091e-02, -1.2426e-01,  3.0594e-02,\n",
      "          8.0213e-02,  6.4655e-03,  7.9442e-02, -4.0186e-02,  2.4083e-02,\n",
      "          6.3794e-03, -1.2226e-01, -1.0979e-01,  6.7254e-03, -1.1619e-01,\n",
      "         -5.8612e-02,  1.1393e-01,  2.0519e-02,  7.7322e-03,  9.1491e-02,\n",
      "         -6.7640e-02,  1.2973e-01,  1.1954e-01,  8.9674e-02,  1.2697e-01,\n",
      "          1.0173e-02, -9.7051e-02, -1.6704e-02,  6.4629e-02],\n",
      "        [ 7.9564e-02,  9.4828e-02, -1.8191e-02, -9.2526e-02,  1.5501e-02,\n",
      "          4.1534e-02, -2.1437e-02,  4.3482e-04, -1.7611e-02,  6.2218e-02,\n",
      "          4.0468e-02, -2.5499e-02,  7.0027e-02,  8.8347e-02, -8.2394e-02,\n",
      "         -1.8136e-02, -2.3372e-02, -9.3215e-02, -9.2676e-02, -6.6475e-02,\n",
      "         -1.0248e-01,  1.0757e-01,  1.7648e-02, -7.1339e-03, -8.1089e-03,\n",
      "          1.0056e-01, -1.8520e-02, -1.5796e-02, -7.6745e-02,  8.7033e-03,\n",
      "         -1.0826e-01, -2.2193e-02, -6.8827e-02,  7.0755e-02,  7.1862e-03,\n",
      "          4.0036e-02, -4.0804e-02,  4.1046e-02, -1.0460e-01,  2.6788e-02,\n",
      "          6.9771e-02,  5.2046e-03,  7.0604e-02, -3.7812e-02,  2.2213e-02,\n",
      "          5.8824e-03, -1.0226e-01, -9.5850e-02,  6.2683e-03, -1.0175e-01,\n",
      "         -4.7529e-02,  9.5102e-02,  1.8535e-02,  7.1733e-03,  7.5691e-02,\n",
      "         -5.8170e-02,  1.1500e-01,  1.0314e-01,  7.5974e-02,  1.0863e-01,\n",
      "          7.8808e-03, -8.2869e-02, -1.5976e-02,  5.6983e-02],\n",
      "        [-9.8135e-02, -9.5074e-02,  3.4569e-03,  1.0746e-01, -1.6297e-02,\n",
      "         -5.6608e-02,  2.6813e-02, -7.3534e-03,  4.7896e-02, -7.2081e-02,\n",
      "         -5.7367e-02,  2.9573e-02, -7.0944e-02, -8.4672e-02,  6.7426e-02,\n",
      "          2.9250e-02,  1.7400e-02,  1.0895e-01,  1.1613e-01,  7.6742e-02,\n",
      "          1.2049e-01, -9.7339e-02, -3.0261e-02,  9.4543e-03,  7.9353e-03,\n",
      "         -1.2688e-01,  2.7198e-02,  3.8079e-02,  9.1818e-02, -1.3347e-02,\n",
      "          1.2047e-01,  1.0339e-03,  7.8532e-02, -7.8110e-02, -1.0347e-02,\n",
      "         -5.8204e-02,  5.7182e-02, -3.7854e-02,  1.2346e-01, -3.1216e-02,\n",
      "         -8.4811e-02,  1.1115e-02, -8.0816e-02,  6.1508e-02, -1.3735e-02,\n",
      "          4.2350e-03,  1.0152e-01,  1.0574e-01,  1.2123e-02,  7.2958e-02,\n",
      "          7.5240e-02, -1.2316e-01, -1.3786e-02,  1.2084e-02, -9.8142e-02,\n",
      "          6.0140e-02, -1.1973e-01, -1.1248e-01, -8.8327e-02, -1.1681e-01,\n",
      "         -6.7865e-03,  8.9029e-02,  8.5482e-03, -3.3188e-02],\n",
      "        [-9.8135e-02, -9.5074e-02,  3.4569e-03,  1.0746e-01, -1.6297e-02,\n",
      "         -5.6608e-02,  2.6813e-02, -7.3534e-03,  4.7896e-02, -7.2081e-02,\n",
      "         -5.7367e-02,  2.9573e-02, -7.0944e-02, -8.4672e-02,  6.7426e-02,\n",
      "          2.9250e-02,  1.7400e-02,  1.0895e-01,  1.1613e-01,  7.6742e-02,\n",
      "          1.2049e-01, -9.7339e-02, -3.0261e-02,  9.4543e-03,  7.9353e-03,\n",
      "         -1.2688e-01,  2.7198e-02,  3.8079e-02,  9.1818e-02, -1.3347e-02,\n",
      "          1.2047e-01,  1.0339e-03,  7.8532e-02, -7.8110e-02, -1.0347e-02,\n",
      "         -5.8204e-02,  5.7182e-02, -3.7854e-02,  1.2346e-01, -3.1216e-02,\n",
      "         -8.4811e-02,  1.1115e-02, -8.0816e-02,  6.1508e-02, -1.3735e-02,\n",
      "          4.2350e-03,  1.0152e-01,  1.0574e-01,  1.2123e-02,  7.2958e-02,\n",
      "          7.5240e-02, -1.2316e-01, -1.3786e-02,  1.2084e-02, -9.8142e-02,\n",
      "          6.0140e-02, -1.1973e-01, -1.1248e-01, -8.8327e-02, -1.1681e-01,\n",
      "         -6.7865e-03,  8.9029e-02,  8.5482e-03, -3.3188e-02],\n",
      "        [-1.0386e-01, -1.0256e-01, -2.4420e-03,  1.1117e-01, -2.1076e-02,\n",
      "         -4.5211e-02,  4.7007e-02, -5.5586e-02,  5.1669e-02, -6.5394e-02,\n",
      "         -5.3700e-02,  4.8402e-02, -9.7608e-02, -1.1893e-01,  6.5572e-02,\n",
      "          2.8383e-02,  2.4258e-03,  1.1000e-01,  1.1366e-01,  8.1314e-02,\n",
      "          1.1625e-01, -1.4665e-01, -1.5303e-02,  2.3351e-03,  1.5828e-02,\n",
      "         -1.2820e-01,  4.4173e-02,  1.9593e-02,  9.9634e-02, -5.3667e-02,\n",
      "          1.2444e-01,  2.7794e-03,  9.2283e-02, -6.5726e-02,  2.5621e-03,\n",
      "         -4.3976e-02,  5.5706e-02, -8.4640e-02,  1.3175e-01, -1.7338e-02,\n",
      "         -9.8298e-02, -7.6400e-03, -6.6064e-02,  5.7081e-02, -3.7058e-02,\n",
      "          5.6870e-03,  1.3563e-01,  1.0852e-01,  1.6185e-02,  7.5736e-02,\n",
      "          6.6309e-02, -1.2021e-01, -2.3191e-02, -3.1543e-03, -1.0169e-01,\n",
      "          6.7656e-02, -1.3350e-01, -1.2802e-01, -1.0579e-01, -1.2914e-01,\n",
      "         -1.7906e-05,  1.1191e-01,  2.2571e-02, -4.3893e-02]], device='cuda:0')\n",
      "\n",
      "Embeddings saved to 'final_embeddings.pt'\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "phase2_score = [] #Holds every node's phase 2 score , index number corresponds to node id\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels , num_layers=3 , dropout = 0.3):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p = self.dropout, training= self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x \n",
    "\n",
    "in_channels = data.num_node_features\n",
    "hidden_channels = 128 \n",
    "out_channels = 64 \n",
    "\n",
    "model = GraphSAGE(in_channels, hidden_channels, out_channels).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr =0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model(data.x, data.edge_index)\n",
    "\n",
    "    pos_edge_index = data.edge_index\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        num_neg_samples=pos_edge_index.size(1),\n",
    "    ).to(device)  \n",
    "\n",
    "    pos_similarity = (z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=1)\n",
    "    pos_loss = F.logsigmoid(pos_similarity).mean()\n",
    "\n",
    "    neg_similarity = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=1)\n",
    "    neg_loss = F.logsigmoid(-neg_similarity).mean()\n",
    "\n",
    "    loss = -pos_loss - neg_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), z\n",
    "\n",
    "print(f\"Training on device: {next(model.parameters()).device}\")\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss, embeddings = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model(data.x, data.edge_index)\n",
    "\n",
    "# saving file\n",
    "    torch.save(z, 'final_embeddings.pt')\n",
    "    print(\"\\nEmbeddings saved to 'final_embeddings.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de765a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 847:\n",
      "  Recipient 5508: score_recipent=2, score_not_recipent=0\n",
      "Node 1311:\n",
      "  Recipient 2761: score_recipent=3, score_not_recipent=19\n",
      "  Recipient 5508: score_recipent=10, score_not_recipent=12\n",
      "Node 1847:\n",
      "  Recipient 679: score_recipent=1, score_not_recipent=44\n",
      "  Recipient 1069: score_recipent=3, score_not_recipent=42\n",
      "  Recipient 1460: score_recipent=3, score_not_recipent=42\n",
      "  Recipient 3042: score_recipent=7, score_not_recipent=38\n",
      "  Recipient 3454: score_recipent=2, score_not_recipent=43\n",
      "  Recipient 4043: score_recipent=2, score_not_recipent=43\n",
      "  Recipient 5355: score_recipent=2, score_not_recipent=43\n",
      "Node 2208:\n",
      "  Recipient 2275: score_recipent=1, score_not_recipent=96\n",
      "  Recipient 2525: score_recipent=1, score_not_recipent=96\n",
      "  Recipient 3401: score_recipent=1, score_not_recipent=96\n",
      "  Recipient 3798: score_recipent=6, score_not_recipent=91\n",
      "Node 2810:\n",
      "  Recipient 1327: score_recipent=2, score_not_recipent=12\n",
      "Node 3862:\n",
      "  Recipient 1789: score_recipent=3, score_not_recipent=53\n",
      "  Recipient 1828: score_recipent=5, score_not_recipent=51\n",
      "  Recipient 3223: score_recipent=4, score_not_recipent=52\n",
      "  Recipient 4072: score_recipent=9, score_not_recipent=47\n",
      "  Recipient 4834: score_recipent=3, score_not_recipent=53\n",
      "  Recipient 5581: score_recipent=5, score_not_recipent=51\n",
      "Node 4043:\n",
      "  Recipient 3442: score_recipent=1, score_not_recipent=16\n",
      "Node 4072:\n",
      "  Recipient 5053: score_recipent=9, score_not_recipent=283\n",
      "Node 4250:\n",
      "  Recipient 5508: score_recipent=2, score_not_recipent=3\n",
      "Node 4415:\n",
      "  Recipient 1327: score_recipent=1, score_not_recipent=0\n",
      "Node 5508:\n",
      "  Recipient 1311: score_recipent=8, score_not_recipent=145\n",
      "  Recipient 5656: score_recipent=8, score_not_recipent=145\n",
      "Node 6055:\n",
      "  Recipient 4072: score_recipent=20, score_not_recipent=348\n",
      "  Recipient 4912: score_recipent=5, score_not_recipent=363\n",
      "  Recipient 6521: score_recipent=10, score_not_recipent=358\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "def historical_pattern(current_day = 200):\n",
    "    csv_file = 'node_day_recipients.csv'\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df[\"day_recipients_str\"] = df[\"day_recipients_str\"].apply(ast.literal_eval)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        node = row['node_id']\n",
    "        day_recipients = row['day_recipients_str']\n",
    "        if (current_day < len(day_recipients) and \n",
    "            len(day_recipients[current_day]) > 0):  \n",
    "            \n",
    "            recipients_today = day_recipients[current_day]\n",
    "            total_score_not_recipent = [0 for _ in range(len(recipients_today))]\n",
    "            total_score_recipent = [0 for _ in range(len(recipients_today))]\n",
    "\n",
    "            for past_day in range(current_day + 1):\n",
    "                if past_day < len(day_recipients) and len(day_recipients[past_day]) > 0:\n",
    "                    for past_recipient in day_recipients[past_day]:\n",
    "                        for j_index, current_recipient in enumerate(recipients_today):\n",
    "                            if past_recipient == current_recipient:\n",
    "                                total_score_recipent[j_index] += 1\n",
    "                            else:\n",
    "                                total_score_not_recipent[j_index] += 1\n",
    "\n",
    "            print(f\"Node {node}:\")\n",
    "            for j_index, recipient in enumerate(recipients_today):\n",
    "                print(f\"  Recipient {recipient}: score_recipent={total_score_recipent[j_index]}, score_not_recipent={total_score_not_recipent[j_index]}\")\n",
    "            \n",
    "       \n",
    "\n",
    "historical_pattern()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51355315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
