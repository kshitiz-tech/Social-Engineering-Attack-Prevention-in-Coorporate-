{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Simple Node-Day Recipients Generator ===\n",
            "Creating node-day structure with recipient lists for each day\n",
            "\n",
            "1. Loading ID-Email mapping...\n",
            "Loaded 6600 email mappings\n",
            "Created mapping for 6600 emails\n",
            "\n",
            "2. Processing emails...\n",
            "Total emails loaded: 517401\n",
            "Emails after filtering: 330689\n",
            "Extracting email information...\n",
            "Row: 0 starting at 2025-10-19 13:06:01.898476.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\barsa\\AppData\\Local\\Temp\\ipykernel_26004\\1130741005.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value ' Mon, 14 May 2001 16:39:00 -0700 (PDT)' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  result_date[row] = message_words[1].replace('Date:', '')\n",
            "C:\\Users\\barsa\\AppData\\Local\\Temp\\ipykernel_26004\\1130741005.py:62: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['phillip.allen@enron.com']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  result_from[row] = re.findall('[\\w\\.-]+@[\\w\\.-]+\\.\\w+', message_words[2])\n",
            "C:\\Users\\barsa\\AppData\\Local\\Temp\\ipykernel_26004\\1130741005.py:68: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['tim.belden@enron.com']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  result_to[row] = re.findall('[\\w\\.-]+@[\\w\\.-]+\\.\\w+', message_words[3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row: 10000 starting at 2025-10-19 13:06:02.067285.\n",
            "Row: 20000 starting at 2025-10-19 13:06:02.234363.\n",
            "Row: 30000 starting at 2025-10-19 13:06:02.389897.\n",
            "Row: 40000 starting at 2025-10-19 13:06:02.554439.\n",
            "Row: 50000 starting at 2025-10-19 13:06:02.745816.\n",
            "Row: 60000 starting at 2025-10-19 13:06:02.942101.\n",
            "Row: 70000 starting at 2025-10-19 13:06:03.122476.\n",
            "Row: 80000 starting at 2025-10-19 13:06:03.286303.\n",
            "Row: 90000 starting at 2025-10-19 13:06:03.438858.\n",
            "Row: 100000 starting at 2025-10-19 13:06:03.600077.\n",
            "Row: 110000 starting at 2025-10-19 13:06:03.767840.\n",
            "Row: 120000 starting at 2025-10-19 13:06:03.919601.\n",
            "Row: 130000 starting at 2025-10-19 13:06:04.079938.\n",
            "Row: 140000 starting at 2025-10-19 13:06:04.241290.\n",
            "Row: 150000 starting at 2025-10-19 13:06:04.418779.\n",
            "Row: 160000 starting at 2025-10-19 13:06:04.583319.\n",
            "Row: 170000 starting at 2025-10-19 13:06:04.743772.\n",
            "Row: 180000 starting at 2025-10-19 13:06:04.901423.\n",
            "Row: 190000 starting at 2025-10-19 13:06:05.057796.\n",
            "Row: 200000 starting at 2025-10-19 13:06:06.294377.\n",
            "Row: 210000 starting at 2025-10-19 13:06:06.451673.\n",
            "Row: 220000 starting at 2025-10-19 13:06:06.609851.\n",
            "Row: 230000 starting at 2025-10-19 13:06:06.763291.\n",
            "Row: 240000 starting at 2025-10-19 13:06:06.920906.\n",
            "Row: 250000 starting at 2025-10-19 13:06:07.073086.\n",
            "Row: 260000 starting at 2025-10-19 13:06:07.236905.\n",
            "Row: 270000 starting at 2025-10-19 13:06:07.389624.\n",
            "Row: 280000 starting at 2025-10-19 13:06:07.555398.\n",
            "Row: 290000 starting at 2025-10-19 13:06:07.709110.\n",
            "Row: 300000 starting at 2025-10-19 13:06:07.867483.\n",
            "Row: 310000 starting at 2025-10-19 13:06:08.022920.\n",
            "Row: 320000 starting at 2025-10-19 13:06:08.176916.\n",
            "Row: 330000 starting at 2025-10-19 13:06:08.327867.\n",
            "Converting dates...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\barsa\\AppData\\Local\\Temp\\ipykernel_26004\\1130741005.py:74: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  result_date = pd.to_datetime(result_date, errors='coerce', utc=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed emails: 330689\n",
            "Filtering by date range...\n",
            "Final email count: 313191\n",
            "3. Creating node-day structure...\n",
            "Created structure for 5776 nodes\n",
            "4. Cleaning and organizing data...\n",
            "5. Converting to output format...\n",
            "Prepared data for 5776 nodes\n",
            "6. Saving to CSV...\n",
            "✓ Saved to node_day_recipients.csv\n",
            "File contains 5776 nodes with 1448 days each\n",
            "\n",
            "=== Statistics ===\n",
            "Total nodes: 5776\n",
            "Total days per node: 1448\n",
            "Average non-empty days per node: 12.78\n",
            "Max non-empty days for any node: 568\n",
            "Min non-empty days for any node: 1\n",
            "\n",
            "=== Sample Structure ===\n",
            "Node 0 first 5 days:\n",
            "  Day 0: []\n",
            "  Day 1: []\n",
            "  Day 2: []\n",
            "  Day 3: []\n",
            "  Day 4: []\n",
            "\n",
            "=== Processing Complete ===\n",
            "✓ File 'node_day_recipients.csv' created successfully!\n",
            "Format: Each row contains node_id and day_recipients_str\n",
            "day_recipients_str is a string representation of a list of 1448 days\n",
            "Each day contains a list of recipient node IDs that received emails from that sender\n"
          ]
        }
      ],
      "source": [
        "# Simple Node-Day Recipients Structure Generator\n",
        "# This creates a CSV where each node has 1448 days of recipient lists\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "import ast\n",
        "\n",
        "print(\"=== Simple Node-Day Recipients Generator ===\")\n",
        "print(\"Creating node-day structure with recipient lists for each day\")\n",
        "print()\n",
        "\n",
        "# 1. Load ID-Email mapping\n",
        "print(\"1. Loading ID-Email mapping...\")\n",
        "id_email_df = pd.read_csv('id-email.csv', header=None, names=['node_id', 'email'])\n",
        "print(f\"Loaded {len(id_email_df)} email mappings\")\n",
        "\n",
        "# Create email to node_id mapping\n",
        "email_to_node = {}\n",
        "for _, row in id_email_df.iterrows():\n",
        "    email_to_node[row['email']] = row['node_id']\n",
        "print(f\"Created mapping for {len(email_to_node)} emails\")\n",
        "print()\n",
        "\n",
        "# 2. Process emails using the proven method\n",
        "print(\"2. Processing emails...\")\n",
        "\n",
        "# Read emails and filter as in the working code\n",
        "emails = pd.read_csv('emails.csv')\n",
        "print(f\"Total emails loaded: {len(emails)}\")\n",
        "\n",
        "# Filter emails (remove discussion threads and auto-emails)\n",
        "emails_nodups = emails[~emails.file.str.contains('discussion_thread', na=False)]\n",
        "emails_noautos = emails_nodups[~emails_nodups.file.str.contains('all_documents', na=False)]\n",
        "emails_noautos = emails_noautos.reset_index(drop=True)\n",
        "print(f\"Emails after filtering: {len(emails_noautos)}\")\n",
        "\n",
        "# Extract email information using proven method\n",
        "print(\"Extracting email information...\")\n",
        "\n",
        "def get_date_from_to(Series):\n",
        "    result_date = pd.Series(index=Series.index)\n",
        "    result_from = pd.Series(index=Series.index)\n",
        "    result_to = pd.Series(index=Series.index)\n",
        "    \n",
        "    for row, message in enumerate(Series):\n",
        "        if row % 10000 == 0:\n",
        "            print(f'Row: {row} starting at {datetime.now()}.')\n",
        "        \n",
        "        message_words = message.split('\\n')\n",
        "        \n",
        "        # Extract date\n",
        "        if len(message_words) > 1 and 'Date:' in message_words[1]:\n",
        "            result_date[row] = message_words[1].replace('Date:', '')\n",
        "        else:\n",
        "            result_date[row] = np.nan\n",
        "        \n",
        "        # Extract sender\n",
        "        if len(message_words) > 2 and 'From:' in message_words[2]:\n",
        "            result_from[row] = re.findall('[\\w\\.-]+@[\\w\\.-]+\\.\\w+', message_words[2])\n",
        "        else:\n",
        "            result_from[row] = np.nan\n",
        "        \n",
        "        # Extract recipient\n",
        "        if len(message_words) > 3 and 'To:' in message_words[3]:\n",
        "            result_to[row] = re.findall('[\\w\\.-]+@[\\w\\.-]+\\.\\w+', message_words[3])\n",
        "        else:\n",
        "            result_to[row] = np.nan\n",
        "    \n",
        "    # Convert dates\n",
        "    print('Converting dates...')\n",
        "    result_date = pd.to_datetime(result_date, errors='coerce', utc=True)\n",
        "    base_date = pd.Timestamp('1999-01-01', tz='UTC')\n",
        "    # Ensure we have a proper Series for arithmetic\n",
        "    result_date = pd.Series(result_date) - base_date\n",
        "    \n",
        "    return result_date, result_from, result_to\n",
        "\n",
        "# Extract email data\n",
        "date_from_to = pd.DataFrame()\n",
        "date_from_to['date'], date_from_to['senders'], date_from_to['recipients'] = get_date_from_to(emails_noautos.message)\n",
        "print(f\"Processed emails: {len(date_from_to)}\")\n",
        "\n",
        "# Filter by date range\n",
        "print(\"Filtering by date range...\")\n",
        "date_from_to.dropna(inplace=True)\n",
        "date_from_to = date_from_to[date_from_to.date >= pd.Timedelta(0)]\n",
        "date_from_to = date_from_to[date_from_to.date <= pd.Timedelta(days=1448)]\n",
        "print(f\"Final email count: {len(date_from_to)}\")\n",
        "\n",
        "# 3. Create node-day structure\n",
        "print(\"3. Creating node-day structure...\")\n",
        "total_days = 1448\n",
        "node_day_structure = defaultdict(lambda: [[] for _ in range(total_days)])\n",
        "\n",
        "# Process each email\n",
        "for index, row in date_from_to.iterrows():\n",
        "    # Check if senders and recipients are not NaN and are lists\n",
        "    if (row.senders is not None and row.senders != [] and \n",
        "        row.recipients is not None and row.recipients != []):\n",
        "        for sender in row.senders:\n",
        "            sender_node = email_to_node.get(sender)\n",
        "            if sender_node is not None:\n",
        "                for recipient in row.recipients:\n",
        "                    recipient_node = email_to_node.get(recipient)\n",
        "                    if recipient_node is not None:\n",
        "                        # Calculate day index\n",
        "                        day_index = int(row.date.days)\n",
        "                        if 0 <= day_index < total_days:\n",
        "                            node_day_structure[sender_node][day_index].append(recipient_node)\n",
        "\n",
        "print(f\"Created structure for {len(node_day_structure)} nodes\")\n",
        "\n",
        "# 4. Clean and organize data\n",
        "print(\"4. Cleaning and organizing data...\")\n",
        "for node_id in node_day_structure:\n",
        "    for day_index in range(total_days):\n",
        "        # Remove duplicates and sort\n",
        "        node_day_structure[node_id][day_index] = sorted(list(set(node_day_structure[node_id][day_index])))\n",
        "\n",
        "# 5. Convert to output format\n",
        "print(\"5. Converting to output format...\")\n",
        "output_data = []\n",
        "for node_id in sorted(node_day_structure.keys()):\n",
        "    day_recipients = node_day_structure[node_id]\n",
        "    output_data.append({\n",
        "        'node_id': node_id,\n",
        "        'day_recipients': day_recipients\n",
        "    })\n",
        "\n",
        "print(f\"Prepared data for {len(output_data)} nodes\")\n",
        "\n",
        "# 6. Save to CSV\n",
        "print(\"6. Saving to CSV...\")\n",
        "output_df = pd.DataFrame(output_data)\n",
        "output_df['day_recipients_str'] = output_df['day_recipients'].apply(lambda x: str(x))\n",
        "output_df[['node_id', 'day_recipients_str']].to_csv('node_day_recipients.csv', index=False)\n",
        "\n",
        "print(\"✓ Saved to node_day_recipients.csv\")\n",
        "print(f\"File contains {len(output_df)} nodes with {total_days} days each\")\n",
        "\n",
        "# 7. Show statistics\n",
        "print(\"\\n=== Statistics ===\")\n",
        "print(f\"Total nodes: {len(output_data)}\")\n",
        "print(f\"Total days per node: {total_days}\")\n",
        "\n",
        "# Count non-empty days\n",
        "non_empty_days = []\n",
        "for node_data in output_data:\n",
        "    non_empty_count = sum(1 for day in node_data['day_recipients'] if day)\n",
        "    non_empty_days.append(non_empty_count)\n",
        "\n",
        "if non_empty_days:\n",
        "    print(f\"Average non-empty days per node: {np.mean(non_empty_days):.2f}\")\n",
        "    print(f\"Max non-empty days for any node: {max(non_empty_days)}\")\n",
        "    print(f\"Min non-empty days for any node: {min(non_empty_days)}\")\n",
        "\n",
        "# Show sample\n",
        "print(\"\\n=== Sample Structure ===\")\n",
        "if output_data:\n",
        "    sample_node = output_data[0]\n",
        "    print(f\"Node {sample_node['node_id']} first 5 days:\")\n",
        "    for i, day in enumerate(sample_node['day_recipients'][:5]):\n",
        "        print(f\"  Day {i}: {day}\")\n",
        "\n",
        "print(\"\\n=== Processing Complete ===\")\n",
        "print(\"✓ File 'node_day_recipients.csv' created successfully!\")\n",
        "print(\"Format: Each row contains node_id and day_recipients_str\")\n",
        "print(\"day_recipients_str is a string representation of a list of 1448 days\")\n",
        "print(\"Each day contains a list of recipient node IDs that received emails from that sender\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
