{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-02T16:34:39.595924Z",
     "iopub.status.busy": "2025-11-02T16:34:39.595355Z",
     "iopub.status.idle": "2025-11-02T16:36:01.767317Z",
     "shell.execute_reply": "2025-11-02T16:36:01.766720Z",
     "shell.execute_reply.started": "2025-11-02T16:34:39.595901Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 5060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (Kaggle doesn't have the latest transformers by default)\n",
    "!pip install -q transformers>=4.40.0\n",
    "!pip install -q torch>=2.1.0\n",
    "\n",
    "# Set environment variable to avoid torchvision issues\n",
    "import os\n",
    "os.environ['TRANSFORMERS_NO_TORCHVISION'] = '1'\n",
    "\n",
    "# Kaggle GPU setup\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "torch._dynamo.config.suppress_errors = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T16:36:01.769352Z",
     "iopub.status.busy": "2025-11-02T16:36:01.768661Z",
     "iopub.status.idle": "2025-11-02T16:36:33.904949Z",
     "shell.execute_reply": "2025-11-02T16:36:33.904139Z",
     "shell.execute_reply.started": "2025-11-02T16:36:01.769332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 1. Co-Attention Layer\n",
    "# ====================================================\n",
    "class CoAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_size=768, k=384):\n",
    "        super().__init__()\n",
    "        self.W_l = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.W_s = nn.Linear(hidden_size, k, bias=False)\n",
    "        self.W_c = nn.Linear(hidden_size, k, bias=False)\n",
    "        self.w_hs = nn.Linear(k, 1, bias=False)\n",
    "        self.w_hc = nn.Linear(k, 1, bias=False)\n",
    "\n",
    "    def forward(self, C, S):\n",
    "        C_t = self.W_l(C)\n",
    "        F = torch.tanh(torch.bmm(C_t, S.transpose(1, 2)))\n",
    "\n",
    "        W_s_S = self.W_s(S)\n",
    "        W_c_C = self.W_c(C)\n",
    "\n",
    "        W_c_C_F = torch.bmm(W_c_C.transpose(1, 2), F)\n",
    "        H_s = torch.tanh(W_s_S.transpose(1, 2) + W_c_C_F)\n",
    "\n",
    "        W_s_S_F_T = torch.bmm(W_s_S.transpose(1, 2), F.transpose(1, 2))\n",
    "        H_c = torch.tanh(W_c_C.transpose(1, 2) + W_s_S_F_T)\n",
    "\n",
    "        a_s = torch.softmax(self.w_hs(H_s.transpose(1, 2)).squeeze(-1), dim=1)\n",
    "        a_c = torch.softmax(self.w_hc(H_c.transpose(1, 2)).squeeze(-1), dim=1)\n",
    "\n",
    "        s_hat = torch.bmm(a_s.unsqueeze(1), S).squeeze(1)\n",
    "        c_hat = torch.bmm(a_c.unsqueeze(1), C).squeeze(1)\n",
    "\n",
    "        return torch.cat([s_hat, c_hat], dim=1)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 2. ModernBERT + Co-Attention Model\n",
    "# ====================================================\n",
    "class ModernBERTCoAttentionModel(nn.Module):\n",
    "    def __init__(self, model_name=\"answerdotai/ModernBERT-base\", k=384, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.bert.gradient_checkpointing_enable()  # VRAM saver\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        self.co_attention = CoAttentionLayer(self.hidden_size, k)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, ids1, mask1, ids2, mask2):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            C = self.bert(ids1, attention_mask=mask1).last_hidden_state\n",
    "            S = self.bert(ids2, attention_mask=mask2).last_hidden_state\n",
    "            z = self.co_attention(C, S)\n",
    "            return self.classifier(z)\n",
    "\n",
    "    def freeze_bert(self):\n",
    "        for p in self.bert.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def unfreeze_bert(self):\n",
    "        for p in self.bert.parameters():\n",
    "            p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T16:36:33.906396Z",
     "iopub.status.busy": "2025-11-02T16:36:33.905815Z",
     "iopub.status.idle": "2025-11-02T16:39:14.663563Z",
     "shell.execute_reply": "2025-11-02T16:39:14.662862Z",
     "shell.execute_reply.started": "2025-11-02T16:36:33.906375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barsa\\AppData\\Local\\Temp\\ipykernel_23876\\928861895.py:252: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 150.98M\n",
      "\n",
      "Stage 1: Training frozen BERT for 3 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/9 [00:00<?, ?it/s]C:\\Users\\barsa\\AppData\\Local\\Temp\\ipykernel_23876\\928861895.py:179: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\barsa\\AppData\\Local\\Temp\\ipykernel_23876\\928861895.py:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "c:\\Users\\barsa\\Documents\\Projects\\Social-Engineering-Attack-Prevention-in-Coorporate-\\GNNProject\\venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Eval:   0%|          | 0/3 [00:00<?, ?it/s]         C:\\Users\\barsa\\AppData\\Local\\Temp\\ipykernel_23876\\928861895.py:204: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train 0.765/0.556, Val 0.328/1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train 0.398/0.778, Val 1.083/0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train 0.094/1.000, Val 1.642/0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train 0.140/0.944, Val 0.064/1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train 0.139/0.944, Val 2.418/0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train 0.147/0.944, Val 0.270/0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train 0.232/0.833, Val 4.316/0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train 0.170/0.944, Val 1.658/0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train 0.009/1.000, Val 0.283/0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train 0.020/1.000, Val 0.526/0.833\n",
      "\n",
      "Stage 2: Fine-tuning full BERT for 2 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train 0.004/1.000, Val 0.812/0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train 0.006/1.000, Val 4.987/0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train 0.043/0.944, Val 4.924/0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train 0.000/1.000, Val 0.002/1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train 0.032/1.000, Val 0.009/1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train 0.000/1.000, Val 1.985/0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train 0.000/1.000, Val 3.503/0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train 0.000/1.000, Val 3.923/0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train 0.000/1.000, Val 4.076/0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train 0.000/1.000, Val 4.119/0.500\n",
      "\n",
      " Training complete. Model saved as modernbert_coattention_local.pt\n",
      "\n",
      "Subject: ALL daily charts and matrices as hot links 5/1\n",
      "Body: The information contained herein is based on sources that we believe to be\n",
      "reliable, but we do not represent that it is accurate or complete.  Nothing\n",
      "contained herein should be considered as an offer to sell or a solicitation\n",
      "of an offer to buy any financial instruments discussed herein.  Any\n",
      "opinions expressed herein are solely those of the author.  As such, they\n",
      "may differ in material respects from those of, or expressed or published by\n",
      "on behalf of Carr Futures or its officers, directors, employees or\n",
      "affiliates.  , 2001 Carr Futures\n",
      "\n",
      "\n",
      "The charts are now available on the web by clicking on the hot link(s)\n",
      "contained in this email. If for any reason you are unable to receive the\n",
      "charts via the web, please contact me via email and I will email the charts\n",
      "to you as attachments.\n",
      "\n",
      "\n",
      "Crude     http://www.carrfut.com/research/Energy1/crude48.pdf\n",
      "Natural Gas     http://www.carrfut.com/research/Energy1/ngas48.pdf\n",
      "Distillate     http://www.carrfut.com/research/Energy1/hoil48.pdf\n",
      "Unleaded     http://www.carrfut.com/research/Energy1/unlded48.pdf\n",
      "\n",
      "Nat Gas Strip Matrix\n",
      "http://www.carrfut.com/research/Energy1/StripmatrixNG48.pdf\n",
      "Nat Gas Spread Matrix\n",
      "http://www.carrfut.com/research/Energy1/SpreadmatrixNG48.pdf\n",
      "\n",
      "Crude and Products Spread Matrix\n",
      "http://www.carrfut.com/research/Energy1/SpreadmatrixCL48.pdf\n",
      "Prediction:  Safe Email  (confidence=0.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barsa\\AppData\\Local\\Temp\\ipykernel_23876\\928861895.py:220: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "class CoAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_size=768, k=384):\n",
    "        super().__init__()\n",
    "        self.W_l = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.W_s = nn.Linear(hidden_size, k, bias=False)\n",
    "        self.W_c = nn.Linear(hidden_size, k, bias=False)\n",
    "        self.w_hs = nn.Linear(k, 1, bias=False)\n",
    "        self.w_hc = nn.Linear(k, 1, bias=False)\n",
    "\n",
    "    def forward(self, C, S):\n",
    "        C_t = self.W_l(C)\n",
    "        F = torch.tanh(torch.bmm(C_t, S.transpose(1, 2)))\n",
    "        W_s_S = self.W_s(S)\n",
    "        W_c_C = self.W_c(C)\n",
    "        W_c_C_F = torch.bmm(W_c_C.transpose(1, 2), F)\n",
    "        H_s = torch.tanh(W_s_S.transpose(1, 2) + W_c_C_F)\n",
    "        W_s_S_F_T = torch.bmm(W_s_S.transpose(1, 2), F.transpose(1, 2))\n",
    "        H_c = torch.tanh(W_c_C.transpose(1, 2) + W_s_S_F_T)\n",
    "        a_s = torch.softmax(self.w_hs(H_s.transpose(1, 2)).squeeze(-1), dim=1)\n",
    "        a_c = torch.softmax(self.w_hc(H_c.transpose(1, 2)).squeeze(-1), dim=1)\n",
    "        s_hat = torch.bmm(a_s.unsqueeze(1), S).squeeze(1)\n",
    "        c_hat = torch.bmm(a_c.unsqueeze(1), C).squeeze(1)\n",
    "        return torch.cat([s_hat, c_hat], dim=1)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 2. ModernBERT + Co-Attention Model (no sigmoid)\n",
    "# ====================================================\n",
    "class ModernBERTCoAttentionModel(nn.Module):\n",
    "    def __init__(self, model_name=\"answerdotai/ModernBERT-base\", k=384, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.bert.gradient_checkpointing_enable()\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        self.co_attention = CoAttentionLayer(self.hidden_size, k)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, ids1, mask1, ids2, mask2):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            C = self.bert(ids1, attention_mask=mask1).last_hidden_state\n",
    "            S = self.bert(ids2, attention_mask=mask2).last_hidden_state\n",
    "            z = self.co_attention(C, S)\n",
    "            return self.classifier(z)\n",
    "\n",
    "    def freeze_bert(self):\n",
    "        for p in self.bert.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def unfreeze_bert(self):\n",
    "        for p in self.bert.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "class SocialEngineeringDataset(Dataset):\n",
    "    def __init__(self, subs, bodies, labels, tokenizer, max_sub_len=256, max_body_len=512):\n",
    "        self.subs = subs\n",
    "        self.bodies = bodies\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_sub_len = max_sub_len\n",
    "        self.max_body_len = max_body_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t1 = self.tokenizer(\n",
    "            self.subs[idx],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_sub_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        t2 = self.tokenizer(\n",
    "            self.bodies[idx],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_body_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids_1\": t1[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask_1\": t1[\"attention_mask\"].squeeze(0),\n",
    "            \"input_ids_2\": t2[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask_2\": t2[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def create_big_social_engineering_data():\n",
    "\n",
    "    \n",
    "    legitimate_subjects = [\n",
    "        \"Weekly Team Meeting - Thursday 2PM\",\n",
    "        \"Q4 Budget Review Documents\",\n",
    "        \"IT Security Training Completion Certificate\",\n",
    "        \"Project Alpha Status Update\",\n",
    "        \"Employee Benefits Open Enrollment Reminder\",\n",
    "        \"Monthly Sales Report - October 2024\",\n",
    "        \"Office Holiday Party Planning Committee\",\n",
    "        \"Performance Review Schedule - November\",\n",
    "        \"New Employee Orientation Materials\",\n",
    "        \"System Maintenance Window This Weekend\",\n",
    "        \"Conference Room Booking Confirmation\",\n",
    "        \"Quarterly All-Hands Meeting Invitation\",\n",
    "    ]\n",
    "    legitimate_bodies = [\n",
    "        \"Hi team, this is a reminder about our weekly meeting scheduled for Thursday at 2:00 PM in Conference Room B. We'll be discussing the current project milestones and next week's deliverables. Please bring your status reports. Thanks, Sarah from HR.\",\n",
    "        \"Please find attached the Q4 budget review documents that were discussed in yesterday's management meeting. The deadline for departmental feedback is November 15th. Contact me if you have questions about the allocation details. Best regards, Finance Department.\",\n",
    "        \"Congratulations on completing the mandatory IT security training. Your certificate is attached to this email. Please save it for your records as it will be needed for your annual performance review. IT Security Team.\",\n",
    "        \"Project Alpha is currently 75% complete and on schedule for the December 1st deadline. All major milestones have been achieved except for the final testing phase. The development team expects to begin testing next Monday. Project Manager.\",\n",
    "        \"Open enrollment for employee benefits begins November 1st and ends November 30th. Please review your current coverage and make any necessary changes during this period. HR will host information sessions every Tuesday this month. Human Resources.\",\n",
    "        \"The October sales report shows a 12% increase compared to September. Regional performance varied with the Northeast leading at 18% growth. Detailed breakdowns are available on the company portal. Sales Operations Team.\",\n",
    "        \"We're forming a committee to plan the annual holiday party scheduled for December 15th. If you're interested in helping with planning, please reply by Friday. We need volunteers for decorations, catering coordination, and entertainment. Social Committee.\",\n",
    "        \"Performance reviews are scheduled for the week of November 20-24. You'll receive a calendar invitation with your specific time slot. Please complete the self-evaluation form before your scheduled meeting. Management Team.\",\n",
    "        \"Welcome materials for new employees starting next week are now available on the company intranet. Managers should review the onboarding checklist to ensure all items are completed during the first week. HR Department.\",\n",
    "        \"Scheduled system maintenance will occur this Saturday from 2:00 AM to 6:00 AM EST. Email and file servers will be unavailable during this time. Please plan accordingly and save your work before Friday evening. IT Operations.\",\n",
    "        \"Your conference room booking for Meeting Room C on November 10th from 1:00-3:00 PM has been confirmed. The room includes video conferencing equipment and accommodates 12 people. Facilities Management.\",\n",
    "        \"You're invited to the quarterly all-hands meeting on Friday, November 17th at 10:00 AM in the main auditorium. The CEO will present Q3 results and discuss strategic initiatives for 2024. Executive Assistant.\",\n",
    "    ]\n",
    "\n",
    "    \n",
    "    malicious_subjects = [\n",
    "        \"URGENT: Verify Your Account Within 24 Hours\",\n",
    "        \"Your Password Will Expire Today - Action Required\",\n",
    "        \"Security Alert: Suspicious Login Detected\",\n",
    "        \"Congratulations! You've Won $50,000\",\n",
    "        \"Important: Update Your Banking Information\",\n",
    "        \"Final Notice: Unpaid Invoice #INV-2024-5847\",\n",
    "        \"Re: Confidential Document Review Needed\",\n",
    "        \"IT Help Desk: Please Confirm Your Credentials\",\n",
    "        \"Payroll Issue: Missing Direct Deposit Information\",\n",
    "        \"CEO Request: Wire Transfer Authorization Needed\",\n",
    "        \"System Upgrade: Temporary Password Reset Required\",\n",
    "        \"HR Investigation: Employee Complaint Filed Against You\",\n",
    "    ]\n",
    "    malicious_bodies = [\n",
    "        \"Your company email account has been flagged for suspicious activity. To prevent account suspension, you must verify your identity immediately. Click here to confirm your login credentials and maintain access to company systems. This verification must be completed within 24 hours or your account will be permanently disabled. IT Security Team (Note: This is not from your real IT department).\",\n",
    "        \"This is an automated reminder that your network password expires today at 5:00 PM. To continue accessing company resources, you must update your password immediately. Click the link below to access the password reset portal and enter your current credentials. Failure to update will result in account lockout. System Administrator (Spoofed sender).\",\n",
    "        \"We detected an unusual login attempt to your account from an unrecognized device in Russia at 3:42 AM EST. If this was not you, please click here immediately to secure your account and change your password. Your account has been temporarily locked for security purposes. Security Operations Center (Fake department).\",\n",
    "        \"Congratulations! Your email address was randomly selected in our international lottery drawing. You have won $50,000 USD. To claim your prize, please provide your full name, address, phone number, and bank account details. Processing fee of $500 required. Contact our claims department immediately. International Lottery Commission (Scam organization).\",\n",
    "        \"Due to new federal banking regulations, we need to update your direct deposit information immediately. Please click here to verify your bank account details and routing number. This update must be completed by end of business today to ensure your next paycheck is processed correctly. Payroll Services (Impersonation attempt).\",\n",
    "        \"This is your final notice for unpaid invoice #INV-2024-5847 in the amount of $2,847.50. Payment is now 60 days overdue. To avoid legal action and additional fees, please remit payment immediately via wire transfer. Contact our collections department at the number below. Accounts Receivable Department (Fake invoice scam).\",\n",
    "        \"I'm forwarding a confidential document that requires your immediate review and approval. Due to the sensitive nature, I cannot send it through normal channels. Please click this secure link and enter your login credentials to access the document. This matter is time-sensitive and confidential. Executive Assistant (CEO impersonation).\",\n",
    "        \"We're conducting routine security updates and need to verify all user accounts. Please reply with your username, password, and security question answers to confirm your account is legitimate. Accounts that don't respond within 48 hours will be deactivated for security reasons. Help Desk Support (Credential harvesting).\",\n",
    "        \"Our payroll system shows missing direct deposit information for your account. Your next paycheck cannot be processed without this update. Please click here to submit your banking details immediately. Contact payroll if you have questions about this urgent matter. Payroll Department (Banking information theft).\",\n",
    "        \"I need you to process an urgent wire transfer of $25,000 to our new vendor for the Johnson project. Due to the time-sensitive nature, please initiate this transfer today and send confirmation. I'm in meetings all day but this cannot wait. Thanks for your quick action on this. CEO (Business Email Compromise).\",\n",
    "        \"As part of our system upgrade, all users must reset their passwords using the new security portal. Click here and enter your current password to generate a new one. This upgrade improves security and must be completed by all employees before Monday. System Administrator (Password harvesting).\",\n",
    "        \"An anonymous complaint has been filed against you regarding workplace conduct. HR requires your immediate response to these allegations. Click here to view the complaint details and submit your response. This matter is confidential and time-sensitive. Human Resources Department (Social engineering for document access).\",\n",
    "    ]\n",
    "\n",
    "    email_subjects = legitimate_subjects + malicious_subjects\n",
    "    email_bodies = legitimate_bodies + malicious_bodies\n",
    "    labels = [0] * len(legitimate_subjects) + [1] * len(malicious_subjects)\n",
    "\n",
    "    return email_subjects, email_bodies, labels\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, opt, crit, device, scaler):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for b in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        ids1 = b[\"input_ids_1\"].to(device)\n",
    "        mask1 = b[\"attention_mask_1\"].to(device)\n",
    "        ids2 = b[\"input_ids_2\"].to(device)\n",
    "        mask2 = b[\"attention_mask_2\"].to(device)\n",
    "        y = b[\"label\"].to(device)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(ids1, mask1, ids2, mask2).view(-1)   \n",
    "            loss = crit(out, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        preds = (torch.sigmoid(out) > 0.5).float()\n",
    "        total_loss += loss.item()\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "        torch.cuda.empty_cache()\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, crit, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for b in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        ids1 = b[\"input_ids_1\"].to(device)\n",
    "        mask1 = b[\"attention_mask_1\"].to(device)\n",
    "        ids2 = b[\"input_ids_2\"].to(device)\n",
    "        mask2 = b[\"attention_mask_2\"].to(device)\n",
    "        y = b[\"label\"].to(device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(ids1, mask1, ids2, mask2).view(-1) \n",
    "            loss = crit(out, y)\n",
    "        preds = (torch.sigmoid(out) > 0.5).float()\n",
    "        total_loss += loss.item()\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_single_email(model, tokenizer, device, subject, body):\n",
    "    model.eval()\n",
    "    t1 = tokenizer(subject, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=256)\n",
    "    t2 = tokenizer(body, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        out = model(\n",
    "            t1[\"input_ids\"].to(device),\n",
    "            t1[\"attention_mask\"].to(device),\n",
    "            t2[\"input_ids\"].to(device),\n",
    "            t2[\"attention_mask\"].to(device),\n",
    "        ).view(-1)\n",
    "        prob = torch.sigmoid(out).item()\n",
    "    label = \"⚠️ Social Engineering\" if prob > 0.5 else \" Safe Email\"\n",
    "    print(f\"\\nSubject: {subject}\\nBody: {body}\\nPrediction: {label}  (confidence={prob:.3f})\")\n",
    "    return prob, label\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "    subs, bodies, labels = create_big_social_engineering_data()\n",
    "    split = int(0.75 * len(labels))\n",
    "    train_data = SocialEngineeringDataset(subs[:split], bodies[:split], labels[:split], tokenizer)\n",
    "    test_data = SocialEngineeringDataset(subs[split:], bodies[split:], labels[split:], tokenizer)\n",
    "    train_loader = DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=2)\n",
    "\n",
    "    model = ModernBERTCoAttentionModel().to(device)\n",
    "    print(f\"Total params: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
    "\n",
    "    \n",
    "    model.freeze_bert()\n",
    "    opt = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-3)\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    print(\"\\nStage 1: Training frozen BERT for 3 epochs...\")\n",
    "    for e in range(10):\n",
    "        tr_loss, tr_acc = train_epoch(model, train_loader, opt, crit, device, scaler)\n",
    "        val_loss, val_acc = evaluate(model, test_loader, crit, device)\n",
    "        print(f\"Epoch {e+1}: Train {tr_loss:.3f}/{tr_acc:.3f}, Val {val_loss:.3f}/{val_acc:.3f}\")\n",
    "\n",
    "    \n",
    "    model.unfreeze_bert()\n",
    "    opt = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    print(\"\\nStage 2: Fine-tuning full BERT for 2 epochs...\")\n",
    "    for e in range(10):\n",
    "        tr_loss, tr_acc = train_epoch(model, train_loader, opt, crit, device, scaler)\n",
    "        val_loss, val_acc = evaluate(model, test_loader, crit, device)\n",
    "        print(f\"Epoch {e+1}: Train {tr_loss:.3f}/{tr_acc:.3f}, Val {val_loss:.3f}/{val_acc:.3f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"modernbert_coattention_local.pt\")\n",
    "    print(\"\\n Training complete. Model saved as modernbert_coattention_local.pt\")\n",
    "\n",
    "    \n",
    "    subject = \"ALL daily charts and matrices as hot links 5/1\"\n",
    "    body = \"\"\"The information contained herein is based on sources that we believe to be\n",
    "reliable, but we do not represent that it is accurate or complete.  Nothing\n",
    "contained herein should be considered as an offer to sell or a solicitation\n",
    "of an offer to buy any financial instruments discussed herein.  Any\n",
    "opinions expressed herein are solely those of the author.  As such, they\n",
    "may differ in material respects from those of, or expressed or published by\n",
    "on behalf of Carr Futures or its officers, directors, employees or\n",
    "affiliates.  , 2001 Carr Futures\n",
    "\n",
    "\n",
    "The charts are now available on the web by clicking on the hot link(s)\n",
    "contained in this email. If for any reason you are unable to receive the\n",
    "charts via the web, please contact me via email and I will email the charts\n",
    "to you as attachments.\n",
    "\n",
    "\n",
    "Crude     http://www.carrfut.com/research/Energy1/crude48.pdf\n",
    "Natural Gas     http://www.carrfut.com/research/Energy1/ngas48.pdf\n",
    "Distillate     http://www.carrfut.com/research/Energy1/hoil48.pdf\n",
    "Unleaded     http://www.carrfut.com/research/Energy1/unlded48.pdf\n",
    "\n",
    "Nat Gas Strip Matrix\n",
    "http://www.carrfut.com/research/Energy1/StripmatrixNG48.pdf\n",
    "Nat Gas Spread Matrix\n",
    "http://www.carrfut.com/research/Energy1/SpreadmatrixNG48.pdf\n",
    "\n",
    "Crude and Products Spread Matrix\n",
    "http://www.carrfut.com/research/Energy1/SpreadmatrixCL48.pdf\"\"\"\n",
    "    test_single_email(model, tokenizer, device, subject, body)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
